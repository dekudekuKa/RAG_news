from pymongo import MongoClient
from bson.objectid import ObjectId
from sentence_transformers import SentenceTransformer
import datetime
import numpy as np

client = MongoClient("mongodb://localhost:27017")
db = client["news_database"]
clean_collection = db["clean_articles"]
vectors_collection = db["vectorized_articles"]
model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")


def vectorize_text(text):
    embedding = model.encode(text)
    return embedding.tolist()


def process_vectors():
    total = 0
    for doc in clean_collection.find():
        print(f"üëÄ –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –¥–æ–∫—É–º–µ–Ω—Ç: {doc.get('raw_id', doc['_id'])}")

        if vectors_collection.find_one({"clean_id": doc["_id"]}):
            print(f"‚è© –í–∂–µ –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–∏–π: {doc['_id']}")
            continue

        clean_text = doc.get("clean_text", "")
        if not clean_text.strip():
            print(f"‚ö†Ô∏è –ü–æ—Ä–æ–∂–Ω—ñ–π clean_text —É –¥–æ–∫—É–º–µ–Ω—Ç—ñ: {doc['_id']}")
            continue

        vector = vectorize_text(clean_text)

        vector_doc = {
            "clean_id": doc["_id"],
            "vector": vector,
            "vectorized_at": datetime.datetime.utcnow()
        }

        vectors_collection.insert_one(vector_doc)
        print(f"‚úÖ –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–æ: {doc.get('raw_id', doc['_id'])}")
        total += 1

    print(f"\nüèÅ –ó–∞–≤–µ—Ä—à–µ–Ω–æ. –í—Å—å–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–æ: {total}")


if __name__ == "__main__":
    process_vectors()

